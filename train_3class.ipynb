{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "from collections import namedtuple\n",
    "import os,glob\n",
    "import random\n",
    "import time\n",
    "\n",
    "import cv2 \n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from natsort import natsorted\n",
    "\n",
    "from ResNet import Bottleneck, ResNet, ResNet50\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransform() :\n",
    "    def __init__(self) :\n",
    "        self.data_transform = {\n",
    "            'train' : transforms.Compose([\n",
    "                # transforms.RandomResizedCrop(resize, scale=(0.5, 1.0)),\n",
    "                # transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize(mean, std)\n",
    "            ]),\n",
    "            'val' : transforms.Compose([\n",
    "                # transforms.Resize(256),\n",
    "                # transforms.CenterCrop(resize),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize(mean, std)\n",
    "            ])\n",
    "        }\n",
    "        \n",
    "    def __call__(self, img, phase) :\n",
    "        return self.data_transform[phase](img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420 53 52\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "red_dir = './new_data_175/red'\n",
    "yellow_dir = './new_data_175/yellow'\n",
    "green_dir = './new_data_175/green'\n",
    "\n",
    "red_images_filepaths = sorted([os.path.join(red_dir, f) for f in os.listdir(red_dir)])\n",
    "yellow_images_filepaths = sorted([os.path.join(yellow_dir, f) for f in os.listdir(yellow_dir)])\n",
    "green_images_filepaths = sorted([os.path.join(green_dir, f) for f in os.listdir(green_dir)])\n",
    "\n",
    "image_filepaths = [*red_images_filepaths, *yellow_images_filepaths, *green_images_filepaths]\n",
    "correct_images_filepaths = [i for i in image_filepaths if cv2.imread(i) is not None]\n",
    "\n",
    "random.seed(50)\n",
    "random.shuffle(correct_images_filepaths)\n",
    "\n",
    "# train_images_filepaths = correct_images_filepaths[:420] # 140 * 3\n",
    "# val_images_filepaths = correct_images_filepaths[420:] # 35 * 3\n",
    "# test_images_filepaths = correct_images_filepaths[420:]\n",
    "train_images_filepaths = correct_images_filepaths[:420] # 140 * 3\n",
    "val_images_filepaths = correct_images_filepaths[420:473] # 35 * 3\n",
    "test_images_filepaths = correct_images_filepaths[473:]\n",
    "\n",
    "print(len(train_images_filepaths), len(val_images_filepaths), len(test_images_filepaths))\n",
    "\n",
    "# label = train_images_filepaths[0].split('/')[-2]\n",
    "# print(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrinalyDataset(Dataset) :\n",
    "    def __init__(self, file_list, transform=None, phase='train') :\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.phase = phase\n",
    "        \n",
    "    def __len__(self) :\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx) :\n",
    "        img_path = self.file_list[idx]\n",
    "        img = Image.open(img_path)\n",
    "        img_transformed = self.transform(img, self.phase)\n",
    "        \n",
    "        # label = img_path.split('/')[-1].split('.')[0]\n",
    "        label = img_path.split('/')[-2]\n",
    "        if label == 'red' :\n",
    "            label = 2\n",
    "            \n",
    "        elif label == 'yellow' :\n",
    "            label = 1\n",
    "\n",
    "        elif label == 'green' :\n",
    "            label = 0\n",
    "            \n",
    "        return img_transformed, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = UrinalyDataset(train_images_filepaths, transform=ImageTransform(),\n",
    "                                 phase='train')\n",
    "val_dataset = UrinalyDataset(val_images_filepaths, transform=ImageTransform(),\n",
    "                               phase='val')\n",
    "index = 0 \n",
    "\n",
    "train_iterator = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_iterator = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "dataloader_dict = {'train' : train_iterator, 'val' : valid_iterator}\n",
    "\n",
    "batch_iterator = iter(train_iterator)\n",
    "inputs, label = next(batch_iterator)\n",
    "\n",
    "# print(inputs.size())\n",
    "# print(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = ResNet50(num_classes=3, channels=1).to(device)\n",
    "optimizer = optim.Adam(Model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_topk_accuracy(y_pred, y, k=2) :\n",
    "    with torch.no_grad() :\n",
    "        batch_size = y.shape[0]\n",
    "        _, top_pred = y_pred.topk(k, 1)\n",
    "        top_pred = top_pred.t()\n",
    "        correct = top_pred.eq(y.view(1, -1).expand_as(top_pred))\n",
    "        correct_1 = correct[:1].reshape(-1).float().sum(0, keepdim=True)\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)        \n",
    "        acc_1 = correct_1 / batch_size\n",
    "        acc_k = correct_k / batch_size\n",
    "    \n",
    "    return acc_1, acc_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, device) :\n",
    "    epoch_loss = 0\n",
    "    epoch_acc_1 = 0\n",
    "    epoch_acc_5 = 0 \n",
    "    model.train()\n",
    "    for (x, y) in iterator :\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        acc_1, acc_5 = calculate_topk_accuracy(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc_1 += acc_1.item()\n",
    "        epoch_acc_5 += acc_5.item()\n",
    "        \n",
    "    epoch_loss /= len(iterator)\n",
    "    epoch_acc_1 /= len(iterator)    \n",
    "    epoch_acc_5 /= len(iterator)  \n",
    "    \n",
    "    return epoch_loss, epoch_acc_1, epoch_acc_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device) :\n",
    "    epoch_loss = 0\n",
    "    epoch_acc_1 = 0\n",
    "    epoch_acc_5 = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad() :\n",
    "        for (x, y) in iterator :\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            \n",
    "            acc_1, acc_5 = calculate_topk_accuracy(y_pred, y)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc_1 += acc_1.item()\n",
    "            epoch_acc_5 += acc_5.item()\n",
    "            \n",
    "        epoch_loss /=len(iterator)\n",
    "        epoch_acc_1 /= len(iterator)\n",
    "        epoch_acc_5 /= len(iterator)\n",
    "        \n",
    "        return epoch_loss, epoch_acc_1, epoch_acc_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time) :\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:80] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 01 | Epoch Time : 6m 26s\n",
      "\tTrain Loss : 0.968 | Train Acc @1 :  52.08% | Train Acc @5 :  83.33%\n",
      "\tValid Loss : 3.431 | Valid Acc @1 :  41.25% | Valid Acc @5 :  79.38%\n",
      "Epoch : 02 | Epoch Time : 6m 17s\n",
      "\tTrain Loss : 0.678 | Train Acc @1 :  67.36% | Train Acc @5 :  96.99%\n",
      "\tValid Loss : 0.674 | Valid Acc @1 :  71.56% | Valid Acc @5 :  90.62%\n",
      "Epoch : 03 | Epoch Time : 6m 15s\n",
      "\tTrain Loss : 0.429 | Train Acc @1 :  81.94% | Train Acc @5 :  97.92%\n",
      "\tValid Loss : 0.304 | Valid Acc @1 :  90.62% | Valid Acc @5 : 100.00%\n",
      "Epoch : 04 | Epoch Time : 6m 17s\n",
      "\tTrain Loss : 0.344 | Train Acc @1 :  87.04% | Train Acc @5 :  99.07%\n",
      "\tValid Loss : 0.443 | Valid Acc @1 :  85.94% | Valid Acc @5 :  95.31%\n",
      "Epoch : 05 | Epoch Time : 6m 16s\n",
      "\tTrain Loss : 0.243 | Train Acc @1 :  90.74% | Train Acc @5 :  98.84%\n",
      "\tValid Loss : 6.240 | Valid Acc @1 :  36.25% | Valid Acc @5 :  76.25%\n",
      "Epoch : 06 | Epoch Time : 6m 17s\n",
      "\tTrain Loss : 0.292 | Train Acc @1 :  90.05% | Train Acc @5 :  99.54%\n",
      "\tValid Loss : 0.382 | Valid Acc @1 :  84.38% | Valid Acc @5 :  98.44%\n",
      "Epoch : 07 | Epoch Time : 6m 16s\n",
      "\tTrain Loss : 0.249 | Train Acc @1 :  92.59% | Train Acc @5 :  99.31%\n",
      "\tValid Loss : 0.800 | Valid Acc @1 :  75.00% | Valid Acc @5 :  98.44%\n",
      "Epoch : 08 | Epoch Time : 6m 15s\n",
      "\tTrain Loss : 0.093 | Train Acc @1 :  97.22% | Train Acc @5 : 100.00%\n",
      "\tValid Loss : 0.307 | Valid Acc @1 :  90.62% | Valid Acc @5 :  98.44%\n",
      "Epoch : 09 | Epoch Time : 6m 16s\n",
      "\tTrain Loss : 0.063 | Train Acc @1 :  98.38% | Train Acc @5 :  99.77%\n",
      "\tValid Loss : 0.705 | Valid Acc @1 :  79.38% | Valid Acc @5 :  93.75%\n",
      "Epoch : 10 | Epoch Time : 6m 14s\n",
      "\tTrain Loss : 0.103 | Train Acc @1 :  96.06% | Train Acc @5 :  99.77%\n",
      "\tValid Loss : 0.445 | Valid Acc @1 :  79.38% | Valid Acc @5 :  98.44%\n",
      "Epoch : 11 | Epoch Time : 6m 16s\n",
      "\tTrain Loss : 0.039 | Train Acc @1 :  99.07% | Train Acc @5 : 100.00%\n",
      "\tValid Loss : 0.283 | Valid Acc @1 :  89.06% | Valid Acc @5 :  98.44%\n",
      "Epoch : 12 | Epoch Time : 6m 16s\n",
      "\tTrain Loss : 0.066 | Train Acc @1 :  98.38% | Train Acc @5 : 100.00%\n",
      "\tValid Loss : 0.882 | Valid Acc @1 :  78.12% | Valid Acc @5 : 100.00%\n",
      "Epoch : 13 | Epoch Time : 6m 17s\n",
      "\tTrain Loss : 0.060 | Train Acc @1 :  98.38% | Train Acc @5 : 100.00%\n",
      "\tValid Loss : 0.531 | Valid Acc @1 :  82.81% | Valid Acc @5 :  95.31%\n",
      "Epoch : 14 | Epoch Time : 6m 17s\n",
      "\tTrain Loss : 0.286 | Train Acc @1 :  94.68% | Train Acc @5 :  98.15%\n",
      "\tValid Loss : 0.425 | Valid Acc @1 :  90.62% | Valid Acc @5 : 100.00%\n",
      "Epoch : 15 | Epoch Time : 6m 14s\n",
      "\tTrain Loss : 0.171 | Train Acc @1 :  93.75% | Train Acc @5 :  99.54%\n",
      "\tValid Loss : 0.838 | Valid Acc @1 :  77.81% | Valid Acc @5 :  92.19%\n",
      "Epoch : 16 | Epoch Time : 6m 12s\n",
      "\tTrain Loss : 0.109 | Train Acc @1 :  95.83% | Train Acc @5 :  99.77%\n",
      "\tValid Loss : 0.509 | Valid Acc @1 :  89.06% | Valid Acc @5 :  96.88%\n",
      "Epoch : 17 | Epoch Time : 6m 15s\n",
      "\tTrain Loss : 0.081 | Train Acc @1 :  97.92% | Train Acc @5 :  99.07%\n",
      "\tValid Loss : 0.514 | Valid Acc @1 :  85.94% | Valid Acc @5 :  92.19%\n",
      "Epoch : 18 | Epoch Time : 6m 15s\n",
      "\tTrain Loss : 0.075 | Train Acc @1 :  97.22% | Train Acc @5 : 100.00%\n",
      "\tValid Loss : 0.818 | Valid Acc @1 :  80.94% | Valid Acc @5 :  91.88%\n",
      "Epoch : 19 | Epoch Time : 6m 15s\n",
      "\tTrain Loss : 0.113 | Train Acc @1 :  95.37% | Train Acc @5 :  99.54%\n",
      "\tValid Loss : 1.466 | Valid Acc @1 :  68.13% | Valid Acc @5 :  92.19%\n",
      "Epoch : 20 | Epoch Time : 6m 17s\n",
      "\tTrain Loss : 0.094 | Train Acc @1 :  96.76% | Train Acc @5 : 100.00%\n",
      "\tValid Loss : 0.532 | Valid Acc @1 :  85.94% | Valid Acc @5 :  95.31%\n",
      "Epoch : 21 | Epoch Time : 6m 17s\n",
      "\tTrain Loss : 0.083 | Train Acc @1 :  96.76% | Train Acc @5 :  99.77%\n",
      "\tValid Loss : 0.597 | Valid Acc @1 :  87.50% | Valid Acc @5 :  93.75%\n",
      "Epoch : 22 | Epoch Time : 6m 14s\n",
      "\tTrain Loss : 0.062 | Train Acc @1 :  97.69% | Train Acc @5 :  99.77%\n",
      "\tValid Loss : 1.621 | Valid Acc @1 :  68.44% | Valid Acc @5 :  90.62%\n",
      "Epoch : 23 | Epoch Time : 6m 21s\n",
      "\tTrain Loss : 0.048 | Train Acc @1 :  98.38% | Train Acc @5 : 100.00%\n",
      "\tValid Loss : 0.673 | Valid Acc @1 :  74.38% | Valid Acc @5 :  98.44%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs) :\n\u001b[1;32m      7\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m----> 9\u001b[0m     train_loss, train_acc_1, train_acc_5 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     valid_loss, valid_acc_1, valid_acc_5 \u001b[38;5;241m=\u001b[39m evaluate(Model, valid_iterator, criterion,\n\u001b[1;32m     12\u001b[0m                                                    device)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m valid_acc_1 \u001b[38;5;241m>\u001b[39m best_valid_acc_1 :\n",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_pred, y)\n\u001b[1;32m     13\u001b[0m acc_1, acc_5 \u001b[38;5;241m=\u001b[39m calculate_topk_accuracy(y_pred, y)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     16\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/task3_hs/lib/python3.8/site-packages/torch/tensor.py:245\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    238\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    239\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    244\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 245\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/task3_hs/lib/python3.8/site-packages/torch/autograd/__init__.py:145\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 145\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Train Model \n",
    "\n",
    "best_valid_acc_1 = 0\n",
    "epochs = 30\n",
    "\n",
    "for epoch in range(epochs) :\n",
    "    start_time = time.monotonic()\n",
    "    \n",
    "    train_loss, train_acc_1, train_acc_5 = train(Model, train_iterator, optimizer,\n",
    "                                                criterion, device)\n",
    "    valid_loss, valid_acc_1, valid_acc_5 = evaluate(Model, valid_iterator, criterion,\n",
    "                                                   device)\n",
    "    \n",
    "    if valid_acc_1 > best_valid_acc_1 :\n",
    "        best_valid_acc_1 = valid_acc_1\n",
    "        torch.save(Model.state_dict(), './experiment/'+str(round(best_valid_acc_1,3))+'_'+str(epoch)+'ResNet-model.pt')\n",
    "        model_lists = natsorted(glob.glob('./experiment/' + '*'), reverse=True)\n",
    "        # while len(model_lists) < 9:\n",
    "        #     os.remove(model_lists[-1])\n",
    "        #     model_lists = natsorted(glob.glob('./experiment/' + '*'))\n",
    "\n",
    "        \n",
    "    end_time = time.monotonic()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch : {epoch+1:02} | Epoch Time : {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss : {train_loss:.3f} | Train Acc @1 : {train_acc_1*100:6.2f}% | Train Acc @5 : {train_acc_5*100:6.2f}%')    \n",
    "    print(f'\\tValid Loss : {valid_loss:.3f} | Valid Acc @1 : {valid_acc_1*100:6.2f}% | Valid Acc @5 : {valid_acc_5*100:6.2f}%')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 0.906_2ResNet-model.pt loaded!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>green</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>red</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>red</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>red</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>red</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>red</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>red</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>red</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>red</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>red</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>red</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>red</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>red</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>red</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>red</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>red</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>red</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>red</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>yellow</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>yellow</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>yellow</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>yellow</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>yellow</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>yellow</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>yellow</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>yellow</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>yellow</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>yellow</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>yellow</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>yellow</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>yellow</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ground_truth    pred\n",
       "0         green   green\n",
       "1         green   green\n",
       "2         green   green\n",
       "3         green   green\n",
       "4         green   green\n",
       "5         green     red\n",
       "6         green   green\n",
       "7         green   green\n",
       "8         green   green\n",
       "9         green   green\n",
       "10        green   green\n",
       "11        green   green\n",
       "12        green   green\n",
       "13        green   green\n",
       "14        green   green\n",
       "15        green   green\n",
       "16        green   green\n",
       "17        green   green\n",
       "18        green   green\n",
       "19        green   green\n",
       "20        green   green\n",
       "21        green   green\n",
       "22          red     red\n",
       "23          red     red\n",
       "24          red     red\n",
       "25          red     red\n",
       "26          red     red\n",
       "27          red     red\n",
       "28          red     red\n",
       "29          red     red\n",
       "30          red     red\n",
       "31          red  yellow\n",
       "32          red   green\n",
       "33          red   green\n",
       "34          red     red\n",
       "35          red     red\n",
       "36          red     red\n",
       "37          red  yellow\n",
       "38          red     red\n",
       "39       yellow  yellow\n",
       "40       yellow  yellow\n",
       "41       yellow  yellow\n",
       "42       yellow  yellow\n",
       "43       yellow  yellow\n",
       "44       yellow  yellow\n",
       "45       yellow  yellow\n",
       "46       yellow     red\n",
       "47       yellow  yellow\n",
       "48       yellow  yellow\n",
       "49       yellow  yellow\n",
       "50       yellow  yellow\n",
       "51       yellow     red"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Eval Model\n",
    "\n",
    "import pandas as pd\n",
    "id_list = []\n",
    "pred_list = []\n",
    "_id = 0\n",
    "\n",
    "model_dir = './experiment/'\n",
    "best_model = torch.load(model_dir + natsorted(os.listdir(model_dir))[-1])\n",
    "print('Model: {} loaded!'.format(natsorted(os.listdir(model_dir))[-1]))\n",
    "Model.load_state_dict(best_model)\n",
    "\n",
    "pred_color = 'None'\n",
    "\n",
    "with torch.no_grad() : \n",
    "    for test_path in test_images_filepaths :\n",
    "        img = Image.open(test_path)\n",
    "        _id = label = test_path.split('/')[-2]\n",
    "        transform = ImageTransform()\n",
    "        img = transform(img, phase='val')\n",
    "        img = img.unsqueeze(0)\n",
    "        img = img.to(device)\n",
    "        \n",
    "        Model.eval()\n",
    "        outputs = Model(img)\n",
    "        # preds = F.softmax(outputs, dim=1)[:, 1].tolist()\n",
    "        preds = F.softmax(outputs, dim=1)\n",
    "        argmax_preds = np.argmax(preds).tolist()\n",
    "        \n",
    "        if argmax_preds == 2 :\n",
    "            pred_color = 'red'\n",
    "        elif argmax_preds == 1 :\n",
    "            pred_color = 'yellow'\n",
    "        elif argmax_preds == 0 :\n",
    "            pred_color = 'green'\n",
    "            \n",
    "        id_list.append(_id)\n",
    "        pred_list.append(pred_color)\n",
    "        \n",
    "res = pd.DataFrame({\n",
    "        'ground_truth' : id_list,\n",
    "        'pred' : pred_list\n",
    "})\n",
    "\n",
    "res.sort_values(by='ground_truth', inplace=True)\n",
    "res.reset_index(drop=True, inplace=True)\n",
    "\n",
    "res.to_csv('./ResNet_eval.csv', index=False)\n",
    "res.head(53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception : (98, 143)\n",
      "Model: 0.906_2ResNet-model.pt loaded!\n",
      "image:  01523651_M_70_2021-03-31_40_1(yellow).jpg\n",
      "pred:  yellow\n"
     ]
    }
   ],
   "source": [
    "# Eval Model 2\n",
    "\n",
    "from preprocessing import crop_resizing_binary\n",
    "\n",
    "file_name = '01523651_M_70_2021-03-31_40_1(yellow).jpg'\n",
    "\n",
    "origin_img = cv2.imread(file_name, cv2.IMREAD_GRAYSCALE)\n",
    "processed_img, _ = crop_resizing_binary(origin_img)\n",
    "\n",
    "model_dir = './experiment/'\n",
    "best_model = torch.load(model_dir + natsorted(os.listdir(model_dir))[-1])\n",
    "print('Model: {} loaded!'.format(natsorted(os.listdir(model_dir))[-1]))\n",
    "Model.load_state_dict(best_model)\n",
    "\n",
    "pred_color = 'None'\n",
    "\n",
    "with torch.no_grad() : \n",
    "        img = processed_img\n",
    "        transform = ImageTransform()\n",
    "        img = transform(img, phase='val')\n",
    "        img = img.unsqueeze(0)\n",
    "        img = img.to(device)\n",
    "        \n",
    "        Model.eval()\n",
    "        outputs = Model(img)\n",
    "        preds = F.softmax(outputs, dim=1)\n",
    "        argmax_preds = np.argmax(preds).tolist()\n",
    "        \n",
    "        if argmax_preds == 2 :\n",
    "            pred_color = 'red'\n",
    "        elif argmax_preds == 1 :\n",
    "            pred_color = 'yellow'\n",
    "        elif argmax_preds == 0 :\n",
    "            pred_color = 'green'\n",
    "\n",
    "        print(\"image: \", file_name)\n",
    "        print(\"pred: \", pred_color)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cau",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
